# ğŸ¦Š Foxa â€” AI-Powered Trading Analytics Lakehouse

> A production-grade **Data Lakehouse** for Indian equities, combining Apache Iceberg, LangGraph multi-agent AI, and the modern data stack.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INGESTION           â”‚  STORAGE (Lakehouse)  â”‚  SERVING          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”€â”€â”€â”€â”€â”€â”€          â”‚
â”‚  Angel One API       â”‚  Bronze â†’ Silver â†’ Goldâ”‚  FastAPI          â”‚
â”‚  Screener.in         â”‚  (Apache Iceberg on    â”‚  DuckDB (OLAP)    â”‚
â”‚  FMP API             â”‚   MinIO S3)            â”‚  Airflow DAGs     â”‚
â”‚  Kafka (optional)    â”‚                       â”‚  MLflow Tracking   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â”‚  AI Agents  â”‚
                    â”‚  LangGraph  â”‚
                    â”‚  ChromaDB   â”‚
                    â”‚  OpenRouter â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

| Layer | Technologies |
|-------|-------------|
| **Storage** | Apache Iceberg Â· MinIO (S3) Â· Parquet Â· SQLite Catalog |
| **Processing** | Polars Â· PyIceberg Â· dbt-duckdb |
| **Data Quality** | Great Expectations |
| **AI Agents** | LangGraph Â· LangChain Â· ChromaDB Â· OpenRouter |
| **API** | FastAPI Â· DuckDB |
| **Orchestration** | Apache Airflow |
| **Tracking** | MLflow Â· LangSmith |
| **Deploy** | Docker Compose |

## Medallion Architecture

```
 BRONZE (Raw)              SILVER (Cleaned)           GOLD (Analytics)
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â€¢ raw OHLCV               â€¢ cleaned OHLCV            â€¢ trading signals
 â€¢ raw fundamentals        â€¢ technical indicators     â€¢ agent analysis
 â€¢ raw news                â€¢ sentiment scores         â€¢ portfolio metrics
                           â€¢ derived features         â€¢ market summary
```

## Project Structure

```
foxa/
â”œâ”€â”€ lakehouse/                  # Data Lakehouse (Iceberg + MinIO)
â”‚   â”œâ”€â”€ minio_client.py         # S3-compatible storage client
â”‚   â”œâ”€â”€ iceberg_catalog.py      # Table catalog + schemas
â”‚   â”œâ”€â”€ bronze.py               # Raw data ingestion
â”‚   â”œâ”€â”€ silver.py               # Cleaning + feature engineering
â”‚   â”œâ”€â”€ gold.py                 # Analytics-ready aggregations
â”‚   â””â”€â”€ pipeline.py             # End-to-end pipeline orchestrator
â”‚
â”œâ”€â”€ agents/                     # AI Agent System
â”‚   â”œâ”€â”€ langgraph_workflow.py   # LangGraph state machine
â”‚   â”œâ”€â”€ state.py                # Agent state definitions
â”‚   â”œâ”€â”€ nodes/                  # Agent nodes (Technical, Fundamental, Risk, Macro, Trader)
â”‚   â”‚   â””â”€â”€ data_loader.py
â”‚   â”œâ”€â”€ fundamental_agent.py    # Fundamental analysis agent
â”‚   â”œâ”€â”€ multi_agent.py          # Multi-agent coordinator
â”‚   â””â”€â”€ tools.py                # Agent tools
â”‚
â”œâ”€â”€ api/                        # REST API
â”‚   â””â”€â”€ main.py                 # FastAPI application
â”‚
â”œâ”€â”€ airflow/                    # Workflow Orchestration
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ lakehouse_pipeline_dag.py
â”‚       â””â”€â”€ signal_generation_dag.py
â”‚
â”œâ”€â”€ data/                       # Data Layer
â”‚   â”œâ”€â”€ ohlcv_fetcher.py        # Market data fetcher
â”‚   â”œâ”€â”€ fundamental_fetcher.py  # Fundamental data fetcher
â”‚   â”œâ”€â”€ market_data.py          # Real-time market data
â”‚   â”œâ”€â”€ technical_indicators.py # Technical analysis library
â”‚   â”œâ”€â”€ stock_universe.py       # Stock universe management
â”‚   â””â”€â”€ kimi_scanner.py         # Strategy scanner
â”‚
â”œâ”€â”€ data_quality/               # Data Quality
â”‚   â””â”€â”€ validation_runner.py    # Great Expectations integration
â”‚
â”œâ”€â”€ great_expectations/         # GE Configuration
â”‚   â”œâ”€â”€ expectations/           # Validation suites
â”‚   â””â”€â”€ checkpoints/            # Validation checkpoints
â”‚
â”œâ”€â”€ dbt_project/                # dbt Transformations
â”‚   â”œâ”€â”€ models/staging/         # Staging models
â”‚   â””â”€â”€ models/marts/           # Business-level marts
â”‚
â”œâ”€â”€ tracking/                   # Experiment Tracking
â”‚   â””â”€â”€ mlflow_utils.py         # MLflow integration
â”‚
â”œâ”€â”€ memory/                     # RAG Memory System
â”œâ”€â”€ knowledge/                  # Knowledge Base
â”œâ”€â”€ llm/                        # LLM Provider
â”œâ”€â”€ database/                   # SQLAlchemy models
â”‚
â”œâ”€â”€ docker-compose.yml          # Full stack deployment
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

## Quick Start

### 1. Clone & Setup

```bash
git clone https://github.com/yourusername/foxa.git
cd foxa
python -m venv venv
venv\Scripts\activate        # Windows
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env with your API keys
```

### 3. Start Infrastructure

```bash
docker-compose up -d          # MinIO + Airflow
```

### 4. Run the Lakehouse Pipeline

```bash
# Initialize Iceberg tables
python -m lakehouse.iceberg_catalog

# Run Bronze â†’ Silver â†’ Gold pipeline
python -m lakehouse.pipeline --symbols RELIANCE TCS INFY

# Run data quality checks
python -m data_quality.validation_runner
```

### 5. Start the API

```bash
uvicorn api.main:app --reload
# â†’ http://localhost:8000/docs
```

### 6. Run LangGraph Agent Analysis

```bash
python -c "
from agents.langgraph_workflow import TradingAgentWorkflow
wf = TradingAgentWorkflow()
result = wf.analyze('RELIANCE')
print(result['final_recommendation'])
"
```

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check |
| `GET` | `/signals` | Latest trading signals |
| `GET` | `/stocks/{symbol}/quote` | Real-time stock quote |
| `POST` | `/analyze` | Run multi-agent analysis |

## Key Features

- **Medallion Lakehouse** â€” Bronze/Silver/Gold zones with Apache Iceberg (ACID, time travel, schema evolution)
- **LangGraph Agents** â€” 6-node multi-agent graph: Data Loader â†’ Technical Analyst â†’ Fundamental Analyst â†’ Risk Manager â†’ Macro Analyst â†’ Trader
- **500+ Stocks** â€” NSE/BSE universe with OHLCV history and fundamentals
- **dbt Models** â€” SQL transformations with lineage tracking
- **Great Expectations** â€” Automated data quality validation
- **MLflow** â€” Experiment tracking for agent performance
- **Airflow DAGs** â€” Scheduled pipeline orchestration

## Skills Demonstrated

| Category | Technologies |
|----------|-------------|
| **Data Lakehouse** | Apache Iceberg, MinIO, Parquet, Medallion Architecture |
| **Modern Data Stack** | dbt-duckdb, Great Expectations, Polars |
| **AI/ML Engineering** | LangGraph, LangChain, ChromaDB, RAG |
| **Data Engineering** | ETL/ELT Pipelines, Schema Evolution, Partitioning |
| **API Development** | FastAPI, Pydantic, REST |
| **MLOps** | MLflow, LangSmith, Experiment Tracking |
| **Orchestration** | Apache Airflow DAGs |
| **DevOps** | Docker, Docker Compose |
| **Domain** | Indian Equities, Technical Analysis, Fundamental Analysis |

## License

MIT
